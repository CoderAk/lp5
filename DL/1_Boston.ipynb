{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall scikit-learn\n",
        "!pip install scikit-learn==1.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4l6CTWBkONq",
        "outputId": "8bedafdf-1045-4587-db36-0ff5f07a0191"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "a7Fxi78tkt7w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_dataset = load_boston()\n",
        "\n",
        "# Create a DataFrame using the dataset's features as column names\n",
        "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
        "\n",
        "# Add the target variable \n",
        "df['MEDV'] = boston_dataset.target\n",
        "\n",
        "x = df.loc[:, df.columns != 'MEDV']\n",
        "y = df.loc[:, df.columns == 'MEDV']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDZ8GIPLkvot",
        "outputId": "f7442dc7-661e-42e5-d367-c8a4472cf3d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=123)\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "mms.fit(x_train)\n",
        "x_train = mms.transform(x_train)\n",
        "x_test = mms.transform(x_test)"
      ],
      "metadata": {
        "id": "Q3INOCUckyPo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xrTNtMijjit",
        "outputId": "496ee8d7-dc22-4e6b-9288-09156db193fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=100, validation_split=0.05, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQWchiWWk7kB",
        "outputId": "59bd8c5c-ff1e-4c18-f762-6f9ff48fc6dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 19ms/step - loss: 592.9975 - mae: 22.5079 - val_loss: 615.8143 - val_mae: 22.9002\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 563.0400 - mae: 21.7990 - val_loss: 578.8121 - val_mae: 22.0419\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 516.7843 - mae: 20.5993 - val_loss: 514.2735 - val_mae: 20.4500\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 437.3408 - mae: 18.4635 - val_loss: 412.4443 - val_mae: 17.6217\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 326.8633 - mae: 15.1077 - val_loss: 283.5143 - val_mae: 13.4857\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 213.7774 - mae: 11.6203 - val_loss: 176.4689 - val_mae: 9.5485\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 152.4592 - mae: 9.6527 - val_loss: 136.5540 - val_mae: 8.5456\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 135.7870 - mae: 9.0780 - val_loss: 123.8072 - val_mae: 8.1561\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 117.2981 - mae: 8.3052 - val_loss: 115.9070 - val_mae: 7.7632\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 102.0972 - mae: 7.5673 - val_loss: 106.3856 - val_mae: 7.3428\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 89.3555 - mae: 6.9680 - val_loss: 97.3736 - val_mae: 6.9440\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 78.4306 - mae: 6.4142 - val_loss: 90.2275 - val_mae: 6.5883\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 70.1106 - mae: 6.0204 - val_loss: 84.2620 - val_mae: 6.3378\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 63.5623 - mae: 5.7904 - val_loss: 79.2515 - val_mae: 6.3696\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.7369 - mae: 5.4996 - val_loss: 77.0029 - val_mae: 6.0827\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55.1768 - mae: 5.2343 - val_loss: 74.1437 - val_mae: 6.0639\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.3073 - mae: 5.0993 - val_loss: 71.6288 - val_mae: 6.1108\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 50.4000 - mae: 4.9996 - val_loss: 69.9369 - val_mae: 6.0042\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 48.4526 - mae: 4.8624 - val_loss: 68.6449 - val_mae: 5.8645\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 46.7928 - mae: 4.7811 - val_loss: 66.7179 - val_mae: 5.8378\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 44.9847 - mae: 4.6765 - val_loss: 65.2157 - val_mae: 5.7462\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 43.1898 - mae: 4.5994 - val_loss: 63.3268 - val_mae: 5.7075\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 41.4425 - mae: 4.5246 - val_loss: 61.2108 - val_mae: 5.6603\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.1215 - mae: 4.3256 - val_loss: 61.0878 - val_mae: 5.3970\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.2065 - mae: 4.2956 - val_loss: 57.0725 - val_mae: 5.5829\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36.3146 - mae: 4.2560 - val_loss: 56.2425 - val_mae: 5.3509\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34.7016 - mae: 4.0290 - val_loss: 55.1886 - val_mae: 5.2065\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33.1258 - mae: 3.9570 - val_loss: 52.3123 - val_mae: 5.2099\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.5079 - mae: 3.9044 - val_loss: 51.7728 - val_mae: 5.0097\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.8509 - mae: 3.7071 - val_loss: 50.0028 - val_mae: 4.9328\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.9183 - mae: 3.7792 - val_loss: 48.0296 - val_mae: 4.8643\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.5407 - mae: 3.5230 - val_loss: 47.5012 - val_mae: 4.7156\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.6962 - mae: 3.5042 - val_loss: 44.1019 - val_mae: 4.7693\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.8582 - mae: 3.4838 - val_loss: 44.8862 - val_mae: 4.6501\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.0071 - mae: 3.2943 - val_loss: 43.4400 - val_mae: 4.6061\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 23.0364 - mae: 3.3168 - val_loss: 41.9779 - val_mae: 4.5745\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.1442 - mae: 3.2517 - val_loss: 42.3270 - val_mae: 4.5289\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 21.4067 - mae: 3.1409 - val_loss: 40.8288 - val_mae: 4.4953\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.7761 - mae: 3.1005 - val_loss: 40.3694 - val_mae: 4.4493\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.3377 - mae: 3.0382 - val_loss: 39.5372 - val_mae: 4.4008\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 19.9785 - mae: 3.0580 - val_loss: 38.7473 - val_mae: 4.3450\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.7740 - mae: 2.9736 - val_loss: 39.5008 - val_mae: 4.2837\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.2758 - mae: 3.0293 - val_loss: 37.4895 - val_mae: 4.2577\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.9168 - mae: 2.9427 - val_loss: 37.9567 - val_mae: 4.2148\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.5799 - mae: 2.9658 - val_loss: 36.6905 - val_mae: 4.1784\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.6999 - mae: 2.9403 - val_loss: 37.2884 - val_mae: 4.1640\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.1401 - mae: 2.9398 - val_loss: 35.6484 - val_mae: 4.1028\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.7953 - mae: 2.8667 - val_loss: 37.4177 - val_mae: 4.0918\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.9553 - mae: 2.9037 - val_loss: 36.0771 - val_mae: 4.0237\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 17.7781 - mae: 2.8535 - val_loss: 34.4855 - val_mae: 3.9721\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 17.4386 - mae: 2.8773 - val_loss: 36.1143 - val_mae: 3.9697\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.4076 - mae: 2.8434 - val_loss: 33.8562 - val_mae: 3.9025\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.1300 - mae: 2.8424 - val_loss: 34.0167 - val_mae: 3.8664\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.2052 - mae: 2.8191 - val_loss: 35.1971 - val_mae: 3.8613\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.7565 - mae: 2.8133 - val_loss: 32.1171 - val_mae: 3.7833\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.7537 - mae: 2.8292 - val_loss: 34.7918 - val_mae: 3.8317\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.8383 - mae: 2.7809 - val_loss: 33.0987 - val_mae: 3.7710\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.5825 - mae: 2.7993 - val_loss: 32.6408 - val_mae: 3.7339\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.4325 - mae: 2.7518 - val_loss: 33.2147 - val_mae: 3.7277\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3854 - mae: 2.7353 - val_loss: 31.3214 - val_mae: 3.6509\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3439 - mae: 2.7647 - val_loss: 32.0381 - val_mae: 3.6524\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.1379 - mae: 2.7450 - val_loss: 31.8591 - val_mae: 3.6371\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.0059 - mae: 2.7204 - val_loss: 31.7630 - val_mae: 3.6097\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.9615 - mae: 2.7209 - val_loss: 30.8481 - val_mae: 3.5498\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.8030 - mae: 2.7088 - val_loss: 32.2457 - val_mae: 3.5890\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.8687 - mae: 2.6978 - val_loss: 31.0155 - val_mae: 3.5254\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.7414 - mae: 2.7245 - val_loss: 30.8331 - val_mae: 3.4982\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.8449 - mae: 2.6729 - val_loss: 29.9927 - val_mae: 3.4405\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.5101 - mae: 2.7165 - val_loss: 29.4557 - val_mae: 3.4049\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.7210 - mae: 2.6828 - val_loss: 29.9529 - val_mae: 3.4160\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.5438 - mae: 2.7125 - val_loss: 29.6770 - val_mae: 3.4030\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.4341 - mae: 2.6853 - val_loss: 28.8520 - val_mae: 3.3497\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.1108 - mae: 2.6312 - val_loss: 30.6028 - val_mae: 3.4308\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0767 - mae: 2.6343 - val_loss: 28.6972 - val_mae: 3.3265\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0859 - mae: 2.6108 - val_loss: 28.9976 - val_mae: 3.3390\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.9455 - mae: 2.6347 - val_loss: 28.3177 - val_mae: 3.2989\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8462 - mae: 2.6065 - val_loss: 28.3162 - val_mae: 3.2885\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.0971 - mae: 2.6961 - val_loss: 29.1932 - val_mae: 3.3275\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.8500 - mae: 2.5711 - val_loss: 27.5477 - val_mae: 3.2307\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6002 - mae: 2.6190 - val_loss: 27.4912 - val_mae: 3.2173\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5391 - mae: 2.5479 - val_loss: 28.6408 - val_mae: 3.2584\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6701 - mae: 2.6031 - val_loss: 27.9449 - val_mae: 3.2225\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.3226 - mae: 2.5444 - val_loss: 26.8591 - val_mae: 3.1575\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.3061 - mae: 2.5858 - val_loss: 27.5834 - val_mae: 3.1876\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1755 - mae: 2.5281 - val_loss: 26.9551 - val_mae: 3.1530\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1466 - mae: 2.5640 - val_loss: 27.4466 - val_mae: 3.1542\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.0703 - mae: 2.5187 - val_loss: 26.3805 - val_mae: 3.1027\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.0841 - mae: 2.5450 - val_loss: 27.2066 - val_mae: 3.1137\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9217 - mae: 2.5220 - val_loss: 26.0620 - val_mae: 3.0581\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9178 - mae: 2.4980 - val_loss: 26.9490 - val_mae: 3.0920\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9137 - mae: 2.5442 - val_loss: 25.8861 - val_mae: 3.0359\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1426 - mae: 2.4881 - val_loss: 25.4599 - val_mae: 3.0286\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.8291 - mae: 2.5614 - val_loss: 25.9547 - val_mae: 3.0002\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.7850 - mae: 2.4920 - val_loss: 25.1754 - val_mae: 2.9827\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.9439 - mae: 2.4936 - val_loss: 25.2510 - val_mae: 2.9735\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 13.5483 - mae: 2.5329 - val_loss: 24.7191 - val_mae: 2.9447\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 13.3288 - mae: 2.4564 - val_loss: 25.7974 - val_mae: 2.9825\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.5852 - mae: 2.5007 - val_loss: 25.6535 - val_mae: 2.9723\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.3814 - mae: 2.4516 - val_loss: 24.8247 - val_mae: 2.9067\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.1661 - mae: 2.4549 - val_loss: 24.4750 - val_mae: 2.8950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f939c31cbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_nn, mae_nn = model.evaluate(x_test, y_test)\n",
        "print('Mean squared error on test data:', mse_nn)\n",
        "print('Mean absolute error on test data:', mae_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjVLWEGHk9fq",
        "outputId": "d7a3a74c-2b57-4d8f-f4ac-c321828a7c34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 7ms/step - loss: 23.1801 - mae: 3.1457\n",
            "Mean squared error on test data: 23.180139541625977\n",
            "Mean absolute error on test data: 3.1457300186157227\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "075e7697b1812e749085b743464b52fb7d88a126d7992be949fc7d73290588b0"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}